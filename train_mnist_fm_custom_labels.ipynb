{"cells":[{"cell_type":"code","execution_count":1,"id":"988baa86-889c-44e4-867d-d3057601c44b","metadata":{"id":"988baa86-889c-44e4-867d-d3057601c44b","executionInfo":{"status":"ok","timestamp":1731340510848,"user_tz":300,"elapsed":22158,"user":{"displayName":"Sushrutha Adari","userId":"11672004475616102517"}}},"outputs":[],"source":["import argparse\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from torchvision import datasets, transforms"]},{"cell_type":"code","execution_count":3,"id":"8e8e38a2-ecea-4b62-a736-cdb39318f935","metadata":{"id":"8e8e38a2-ecea-4b62-a736-cdb39318f935","executionInfo":{"status":"ok","timestamp":1731340582865,"user_tz":300,"elapsed":193,"user":{"displayName":"Sushrutha Adari","userId":"11672004475616102517"}}},"outputs":[],"source":["# Simulate arguments using argparse.Namespace\n","args = argparse.Namespace(\n","    seed=1,\n","    seed_data=1,\n","    unlabeled_weight=1.0,\n","    batch_size=100,\n","    count=10,\n","    balance=True,\n","    epochs=300,\n","    labels='/path/to/labels/file'  # specify the correct path for the labels file\n",")\n","\n","\n"]},{"cell_type":"code","execution_count":4,"id":"9eba7d0e-b3ce-40ef-8150-c6cedb8dd58e","metadata":{"id":"9eba7d0e-b3ce-40ef-8150-c6cedb8dd58e","executionInfo":{"status":"ok","timestamp":1731340641416,"user_tz":300,"elapsed":190,"user":{"displayName":"Sushrutha Adari","userId":"11672004475616102517"}}},"outputs":[],"source":["# Seed setting\n","torch.manual_seed(args.seed)\n","np.random.seed(args.seed_data)"]},{"cell_type":"code","execution_count":5,"id":"38e00953-c0a7-463f-8bcf-e470fdf5a013","metadata":{"id":"38e00953-c0a7-463f-8bcf-e470fdf5a013","executionInfo":{"status":"ok","timestamp":1731340643159,"user_tz":300,"elapsed":185,"user":{"displayName":"Sushrutha Adari","userId":"11672004475616102517"}}},"outputs":[],"source":["# Gaussian Noise Layer\n","class GaussianNoise(nn.Module):\n","    def __init__(self, sigma):\n","        super(GaussianNoise, self).__init__()\n","        self.sigma = sigma\n","\n","    def forward(self, x):\n","        if self.training:  # Only add noise during training\n","            noise = torch.randn_like(x) * self.sigma\n","            return x + noise\n","        return x"]},{"cell_type":"code","execution_count":6,"id":"07c06177-e437-41d7-9cfe-ce6ddb2189a7","metadata":{"id":"07c06177-e437-41d7-9cfe-ce6ddb2189a7","executionInfo":{"status":"ok","timestamp":1731340646639,"user_tz":300,"elapsed":190,"user":{"displayName":"Sushrutha Adari","userId":"11672004475616102517"}}},"outputs":[],"source":["# Generator Model\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        self.fc1 = nn.Sequential(nn.Linear(100, 500), nn.Softplus())\n","        self.fc2 = nn.Sequential(nn.Linear(500, 500), nn.Softplus())\n","        self.fc3 = nn.Linear(500, 28*28)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","        x = self.sigmoid(self.fc3(x))\n","        return x"]},{"cell_type":"code","execution_count":7,"id":"2bcb9c78-379b-4d5a-80ce-0e299b93c90c","metadata":{"id":"2bcb9c78-379b-4d5a-80ce-0e299b93c90c","executionInfo":{"status":"ok","timestamp":1731340650609,"user_tz":300,"elapsed":191,"user":{"displayName":"Sushrutha Adari","userId":"11672004475616102517"}}},"outputs":[],"source":["# Discriminator Model\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.fc1 = nn.Sequential(nn.Linear(28*28, 1000), GaussianNoise(0.3))\n","        self.fc2 = nn.Sequential(nn.Linear(1000, 500), GaussianNoise(0.5))\n","        self.fc3 = nn.Sequential(nn.Linear(500, 250), GaussianNoise(0.5))\n","        self.fc4 = nn.Sequential(nn.Linear(250, 250), GaussianNoise(0.5))\n","        self.fc5 = nn.Linear(250, 10)  # No noise on the last layer\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), -1)  # Flatten input\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","        x = self.fc3(x)\n","        x = self.fc4(x)\n","        x = self.fc5(x)\n","        return x"]},{"cell_type":"code","execution_count":8,"id":"47c53967-8dbc-4402-8594-cf08ed62536b","metadata":{"id":"47c53967-8dbc-4402-8594-cf08ed62536b","executionInfo":{"status":"ok","timestamp":1731340653510,"user_tz":300,"elapsed":175,"user":{"displayName":"Sushrutha Adari","userId":"11672004475616102517"}}},"outputs":[],"source":["# Instantiate models\n","gen = Generator()\n","disc = Discriminator()\n"]},{"cell_type":"code","execution_count":9,"id":"f21a80e1-7f31-4595-acc9-0e16e44224b9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f21a80e1-7f31-4595-acc9-0e16e44224b9","executionInfo":{"status":"ok","timestamp":1731340655862,"user_tz":300,"elapsed":176,"user":{"displayName":"Sushrutha Adari","userId":"11672004475616102517"}},"outputId":"554d4a62-eb1b-4ee5-c6bf-a146333cd7f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generator(\n","  (fc1): Sequential(\n","    (0): Linear(in_features=100, out_features=500, bias=True)\n","    (1): Softplus(beta=1.0, threshold=20.0)\n","  )\n","  (fc2): Sequential(\n","    (0): Linear(in_features=500, out_features=500, bias=True)\n","    (1): Softplus(beta=1.0, threshold=20.0)\n","  )\n","  (fc3): Linear(in_features=500, out_features=784, bias=True)\n","  (sigmoid): Sigmoid()\n",")\n","Discriminator(\n","  (fc1): Sequential(\n","    (0): Linear(in_features=784, out_features=1000, bias=True)\n","    (1): GaussianNoise()\n","  )\n","  (fc2): Sequential(\n","    (0): Linear(in_features=1000, out_features=500, bias=True)\n","    (1): GaussianNoise()\n","  )\n","  (fc3): Sequential(\n","    (0): Linear(in_features=500, out_features=250, bias=True)\n","    (1): GaussianNoise()\n","  )\n","  (fc4): Sequential(\n","    (0): Linear(in_features=250, out_features=250, bias=True)\n","    (1): GaussianNoise()\n","  )\n","  (fc5): Linear(in_features=250, out_features=10, bias=True)\n",")\n"]}],"source":["# Check the models\n","print(gen)\n","print(disc)"]},{"cell_type":"code","execution_count":10,"id":"ed036311-7cdc-44c6-8494-bd75e7acae6d","metadata":{"id":"ed036311-7cdc-44c6-8494-bd75e7acae6d","executionInfo":{"status":"ok","timestamp":1731340659419,"user_tz":300,"elapsed":183,"user":{"displayName":"Sushrutha Adari","userId":"11672004475616102517"}}},"outputs":[],"source":["# Loss and optimizers\n","criterion = nn.CrossEntropyLoss()\n","gen_optimizer = optim.Adam(gen.parameters(), lr=0.003)\n","disc_optimizer = optim.Adam(disc.parameters(), lr=0.003)"]},{"cell_type":"code","execution_count":11,"id":"fdf9f28b-2bcf-4958-a7a1-70105cc52804","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"fdf9f28b-2bcf-4958-a7a1-70105cc52804","executionInfo":{"status":"ok","timestamp":1731340669155,"user_tz":300,"elapsed":4865,"user":{"displayName":"Sushrutha Adari","userId":"11672004475616102517"}},"outputId":"93f64e46-c8d0-4061-f73f-49a2b967b500"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 17.5MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28.9k/28.9k [00:00<00:00, 537kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1.65M/1.65M [00:00<00:00, 4.76MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4.54k/4.54k [00:00<00:00, 8.43MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# Load MNIST data\n","transform = transforms.ToTensor()\n","train_data = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n","train_loader = DataLoader(train_data, batch_size=args.batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":12,"id":"a0566699-e085-4251-a748-81e8bfd2b1ad","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a0566699-e085-4251-a748-81e8bfd2b1ad","executionInfo":{"status":"ok","timestamp":1731345862485,"user_tz":300,"elapsed":5186016,"user":{"displayName":"Sushrutha Adari","userId":"11672004475616102517"}},"outputId":"52f77d48-8a3a-43e1-d4a8-fa429e260acc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/300], Loss D: 0.4705, Loss G: 66.0365\n","Epoch [2/300], Loss D: 0.3871, Loss G: 58.5213\n","Epoch [3/300], Loss D: 0.5339, Loss G: 42.1819\n","Epoch [4/300], Loss D: 0.3926, Loss G: 54.6667\n","Epoch [5/300], Loss D: 0.3469, Loss G: 47.6688\n","Epoch [6/300], Loss D: 0.3699, Loss G: 34.8319\n","Epoch [7/300], Loss D: 0.3384, Loss G: 39.5131\n","Epoch [8/300], Loss D: 0.4349, Loss G: 37.9348\n","Epoch [9/300], Loss D: 0.2642, Loss G: 70.7694\n","Epoch [10/300], Loss D: 0.4409, Loss G: 45.7264\n","Epoch [11/300], Loss D: 0.1207, Loss G: 33.7912\n","Epoch [12/300], Loss D: 0.2200, Loss G: 52.4639\n","Epoch [13/300], Loss D: 0.4436, Loss G: 44.0737\n","Epoch [14/300], Loss D: 0.1933, Loss G: 83.0517\n","Epoch [15/300], Loss D: 0.3092, Loss G: 74.6155\n","Epoch [16/300], Loss D: 0.3044, Loss G: 94.3061\n","Epoch [17/300], Loss D: 0.2052, Loss G: 56.4323\n","Epoch [18/300], Loss D: 0.2800, Loss G: 73.9703\n","Epoch [19/300], Loss D: 0.1432, Loss G: 63.5228\n","Epoch [20/300], Loss D: 0.3599, Loss G: 60.0644\n","Epoch [21/300], Loss D: 0.2256, Loss G: 78.8735\n","Epoch [22/300], Loss D: 0.7345, Loss G: 71.0749\n","Epoch [23/300], Loss D: 0.1818, Loss G: 72.9334\n","Epoch [24/300], Loss D: 0.2950, Loss G: 75.4453\n","Epoch [25/300], Loss D: 0.1173, Loss G: 65.6266\n","Epoch [26/300], Loss D: 2.8214, Loss G: 195.0510\n","Epoch [27/300], Loss D: 14.4362, Loss G: 3539.9319\n","Epoch [28/300], Loss D: 1.0005, Loss G: 1799.5752\n","Epoch [29/300], Loss D: 0.1545, Loss G: 1053.6249\n","Epoch [30/300], Loss D: 1.2282, Loss G: 818.9227\n","Epoch [31/300], Loss D: 0.6052, Loss G: 1018.5610\n","Epoch [32/300], Loss D: 0.2918, Loss G: 588.9529\n","Epoch [33/300], Loss D: 0.5516, Loss G: 649.1412\n","Epoch [34/300], Loss D: 0.1351, Loss G: 440.0058\n","Epoch [35/300], Loss D: 0.2763, Loss G: 319.1980\n","Epoch [36/300], Loss D: 0.5679, Loss G: 396.0369\n","Epoch [37/300], Loss D: 0.3330, Loss G: 357.8197\n","Epoch [38/300], Loss D: 0.1360, Loss G: 271.5426\n","Epoch [39/300], Loss D: 0.0945, Loss G: 297.7459\n","Epoch [40/300], Loss D: 0.1374, Loss G: 280.4293\n","Epoch [41/300], Loss D: 0.1409, Loss G: 256.1535\n","Epoch [42/300], Loss D: 0.1177, Loss G: 260.0514\n","Epoch [43/300], Loss D: 0.2027, Loss G: 353.1635\n","Epoch [44/300], Loss D: 0.0976, Loss G: 291.0778\n","Epoch [45/300], Loss D: 0.3749, Loss G: 327.5233\n","Epoch [46/300], Loss D: 0.0865, Loss G: 287.7600\n","Epoch [47/300], Loss D: 0.3342, Loss G: 268.4436\n","Epoch [48/300], Loss D: 0.1887, Loss G: 275.1109\n","Epoch [49/300], Loss D: 0.0548, Loss G: 300.8651\n","Epoch [50/300], Loss D: 0.4271, Loss G: 229.0224\n","Epoch [51/300], Loss D: 0.0992, Loss G: 178.3594\n","Epoch [52/300], Loss D: 0.1590, Loss G: 242.9298\n","Epoch [53/300], Loss D: 0.2500, Loss G: 263.1654\n","Epoch [54/300], Loss D: 0.1250, Loss G: 272.4980\n","Epoch [55/300], Loss D: 0.0962, Loss G: 209.1541\n","Epoch [56/300], Loss D: 0.1725, Loss G: 257.5099\n","Epoch [57/300], Loss D: 0.0545, Loss G: 295.2150\n","Epoch [58/300], Loss D: 0.1445, Loss G: 297.9826\n","Epoch [59/300], Loss D: 0.0801, Loss G: 253.6507\n","Epoch [60/300], Loss D: 0.1642, Loss G: 210.7808\n","Epoch [61/300], Loss D: 0.1345, Loss G: 193.7650\n","Epoch [62/300], Loss D: 0.1026, Loss G: 214.9838\n","Epoch [63/300], Loss D: 0.0969, Loss G: 205.5441\n","Epoch [64/300], Loss D: 0.0385, Loss G: 272.3722\n","Epoch [65/300], Loss D: 0.0299, Loss G: 153.1120\n","Epoch [66/300], Loss D: 0.1539, Loss G: 192.9490\n","Epoch [67/300], Loss D: 0.1896, Loss G: 150.2996\n","Epoch [68/300], Loss D: 0.2233, Loss G: 167.6598\n","Epoch [69/300], Loss D: 0.4181, Loss G: 187.4922\n","Epoch [70/300], Loss D: 0.0826, Loss G: 178.6204\n","Epoch [71/300], Loss D: 0.1208, Loss G: 119.2333\n","Epoch [72/300], Loss D: 0.1282, Loss G: 151.4876\n","Epoch [73/300], Loss D: 0.0793, Loss G: 205.5794\n","Epoch [74/300], Loss D: 0.3616, Loss G: 65.7324\n","Epoch [75/300], Loss D: 0.0671, Loss G: 136.3447\n","Epoch [76/300], Loss D: 0.4371, Loss G: 119.3101\n","Epoch [77/300], Loss D: 0.1266, Loss G: 117.6566\n","Epoch [78/300], Loss D: 0.0391, Loss G: 79.8588\n","Epoch [79/300], Loss D: 0.4224, Loss G: 104.1132\n","Epoch [80/300], Loss D: 0.2277, Loss G: 91.1239\n","Epoch [81/300], Loss D: 0.3857, Loss G: 263.2800\n","Epoch [82/300], Loss D: 0.0443, Loss G: 185.6004\n","Epoch [83/300], Loss D: 0.0655, Loss G: 163.0152\n","Epoch [84/300], Loss D: 0.1631, Loss G: 135.9102\n","Epoch [85/300], Loss D: 0.1330, Loss G: 130.8597\n","Epoch [86/300], Loss D: 0.1286, Loss G: 73.4062\n","Epoch [87/300], Loss D: 0.1316, Loss G: 119.3632\n","Epoch [88/300], Loss D: 0.1248, Loss G: 102.9374\n","Epoch [89/300], Loss D: 0.2818, Loss G: 80.6934\n","Epoch [90/300], Loss D: 0.1349, Loss G: 186.7545\n","Epoch [91/300], Loss D: 0.1174, Loss G: 158.2913\n","Epoch [92/300], Loss D: 0.2013, Loss G: 111.3395\n","Epoch [93/300], Loss D: 0.2693, Loss G: 135.6839\n","Epoch [94/300], Loss D: 0.0494, Loss G: 78.6258\n","Epoch [95/300], Loss D: 0.1672, Loss G: 130.8029\n","Epoch [96/300], Loss D: 0.2160, Loss G: 69.4429\n","Epoch [97/300], Loss D: 0.1826, Loss G: 73.3691\n","Epoch [98/300], Loss D: 0.1706, Loss G: 71.4891\n","Epoch [99/300], Loss D: 0.1212, Loss G: 70.7005\n","Epoch [100/300], Loss D: 0.2144, Loss G: 70.1426\n","Epoch [101/300], Loss D: 0.1663, Loss G: 75.3141\n","Epoch [102/300], Loss D: 0.2954, Loss G: 57.4216\n","Epoch [103/300], Loss D: 0.0695, Loss G: 63.2742\n","Epoch [104/300], Loss D: 0.1817, Loss G: 93.5204\n","Epoch [105/300], Loss D: 0.0577, Loss G: 105.5305\n","Epoch [106/300], Loss D: 0.0567, Loss G: 112.9965\n","Epoch [107/300], Loss D: 0.1406, Loss G: 125.2815\n","Epoch [108/300], Loss D: 0.1469, Loss G: 89.0051\n","Epoch [109/300], Loss D: 0.1890, Loss G: 60.9493\n","Epoch [110/300], Loss D: 0.1415, Loss G: 87.0193\n","Epoch [111/300], Loss D: 0.1632, Loss G: 64.5666\n","Epoch [112/300], Loss D: 0.2543, Loss G: 134.5207\n","Epoch [113/300], Loss D: 0.0800, Loss G: 91.6227\n","Epoch [114/300], Loss D: 0.1856, Loss G: 115.7656\n","Epoch [115/300], Loss D: 0.2484, Loss G: 92.0192\n","Epoch [116/300], Loss D: 0.1750, Loss G: 123.4034\n","Epoch [117/300], Loss D: 0.1896, Loss G: 77.1220\n","Epoch [118/300], Loss D: 0.0671, Loss G: 48.7262\n","Epoch [119/300], Loss D: 0.1304, Loss G: 83.2540\n","Epoch [120/300], Loss D: 0.1302, Loss G: 130.7095\n","Epoch [121/300], Loss D: 0.1246, Loss G: 93.4460\n","Epoch [122/300], Loss D: 0.2227, Loss G: 78.5354\n","Epoch [123/300], Loss D: 0.0866, Loss G: 69.6089\n","Epoch [124/300], Loss D: 0.2317, Loss G: 64.1820\n","Epoch [125/300], Loss D: 0.2013, Loss G: 105.2429\n","Epoch [126/300], Loss D: 0.4081, Loss G: 106.5183\n","Epoch [127/300], Loss D: 0.0741, Loss G: 111.7546\n","Epoch [128/300], Loss D: 0.3984, Loss G: 131.0727\n","Epoch [129/300], Loss D: 416.2972, Loss G: 15934.8525\n","Epoch [130/300], Loss D: 6.8612, Loss G: 4617.2583\n","Epoch [131/300], Loss D: 0.3545, Loss G: 4301.9121\n","Epoch [132/300], Loss D: 0.8702, Loss G: 1426.8495\n","Epoch [133/300], Loss D: 0.3050, Loss G: 1544.7316\n","Epoch [134/300], Loss D: 0.8657, Loss G: 1566.5585\n","Epoch [135/300], Loss D: 0.2245, Loss G: 1108.0175\n","Epoch [136/300], Loss D: 0.1894, Loss G: 869.5159\n","Epoch [137/300], Loss D: 0.7681, Loss G: 1071.4800\n","Epoch [138/300], Loss D: 0.0094, Loss G: 894.1697\n","Epoch [139/300], Loss D: 0.2525, Loss G: 719.0698\n","Epoch [140/300], Loss D: 0.6970, Loss G: 1046.9890\n","Epoch [141/300], Loss D: 0.0324, Loss G: 839.3467\n","Epoch [142/300], Loss D: 0.2382, Loss G: 1013.3926\n","Epoch [143/300], Loss D: 0.0841, Loss G: 837.4280\n","Epoch [144/300], Loss D: 0.0451, Loss G: 813.1362\n","Epoch [145/300], Loss D: 0.5403, Loss G: 837.0037\n","Epoch [146/300], Loss D: 0.0116, Loss G: 1037.7864\n","Epoch [147/300], Loss D: 0.1898, Loss G: 664.8370\n","Epoch [148/300], Loss D: 0.3259, Loss G: 681.6763\n","Epoch [149/300], Loss D: 0.1415, Loss G: 1612.4827\n","Epoch [150/300], Loss D: 0.0065, Loss G: 794.0345\n","Epoch [151/300], Loss D: 0.0029, Loss G: 740.3592\n","Epoch [152/300], Loss D: 0.0462, Loss G: 668.3677\n","Epoch [153/300], Loss D: 0.4143, Loss G: 758.3961\n","Epoch [154/300], Loss D: 0.3772, Loss G: 553.8220\n","Epoch [155/300], Loss D: 0.2502, Loss G: 719.2673\n","Epoch [156/300], Loss D: 0.0039, Loss G: 780.6370\n","Epoch [157/300], Loss D: 0.0482, Loss G: 588.8676\n","Epoch [158/300], Loss D: 0.1415, Loss G: 688.5718\n","Epoch [159/300], Loss D: 0.0413, Loss G: 599.2780\n","Epoch [160/300], Loss D: 0.0682, Loss G: 654.7068\n","Epoch [161/300], Loss D: 0.1399, Loss G: 594.0876\n","Epoch [162/300], Loss D: 0.0814, Loss G: 784.7420\n","Epoch [163/300], Loss D: 0.0957, Loss G: 467.5614\n","Epoch [164/300], Loss D: 0.1163, Loss G: 624.7606\n","Epoch [165/300], Loss D: 0.1610, Loss G: 561.8354\n","Epoch [166/300], Loss D: 0.1932, Loss G: 348.5682\n","Epoch [167/300], Loss D: 0.1212, Loss G: 363.1418\n","Epoch [168/300], Loss D: 0.1095, Loss G: 617.6097\n","Epoch [169/300], Loss D: 0.0283, Loss G: 323.8058\n","Epoch [170/300], Loss D: 0.0790, Loss G: 599.9400\n","Epoch [171/300], Loss D: 0.0044, Loss G: 288.2386\n","Epoch [172/300], Loss D: 0.1614, Loss G: 681.6139\n","Epoch [173/300], Loss D: 0.0699, Loss G: 278.9219\n","Epoch [174/300], Loss D: 0.1552, Loss G: 375.7924\n","Epoch [175/300], Loss D: 0.1673, Loss G: 529.6104\n","Epoch [176/300], Loss D: 0.3842, Loss G: 319.6424\n","Epoch [177/300], Loss D: 0.1156, Loss G: 423.9040\n","Epoch [178/300], Loss D: 0.0542, Loss G: 470.2751\n","Epoch [179/300], Loss D: 0.1631, Loss G: 339.2952\n","Epoch [180/300], Loss D: 0.1452, Loss G: 344.1167\n","Epoch [181/300], Loss D: 0.0396, Loss G: 270.8732\n","Epoch [182/300], Loss D: 0.2757, Loss G: 158.5190\n","Epoch [183/300], Loss D: 0.1214, Loss G: 460.2302\n","Epoch [184/300], Loss D: 0.1494, Loss G: 461.3609\n","Epoch [185/300], Loss D: 0.1981, Loss G: 373.3534\n","Epoch [186/300], Loss D: 0.1456, Loss G: 344.3515\n","Epoch [187/300], Loss D: 0.0354, Loss G: 114.2730\n","Epoch [188/300], Loss D: 0.0615, Loss G: 261.6277\n","Epoch [189/300], Loss D: 0.0205, Loss G: 272.1144\n","Epoch [190/300], Loss D: 0.0928, Loss G: 476.4110\n","Epoch [191/300], Loss D: 0.2069, Loss G: 708.6516\n","Epoch [192/300], Loss D: 0.4413, Loss G: 360.1290\n","Epoch [193/300], Loss D: 0.3539, Loss G: 249.4474\n","Epoch [194/300], Loss D: 0.1251, Loss G: 166.3857\n","Epoch [195/300], Loss D: 0.1135, Loss G: 298.5206\n","Epoch [196/300], Loss D: 0.1406, Loss G: 208.7699\n","Epoch [197/300], Loss D: 0.0989, Loss G: 263.9273\n","Epoch [198/300], Loss D: 0.0621, Loss G: 313.0326\n","Epoch [199/300], Loss D: 0.0337, Loss G: 219.1246\n","Epoch [200/300], Loss D: 0.0453, Loss G: 293.9392\n","Epoch [201/300], Loss D: 0.0154, Loss G: 255.0703\n","Epoch [202/300], Loss D: 0.0662, Loss G: 330.9721\n","Epoch [203/300], Loss D: 0.1996, Loss G: 398.2175\n","Epoch [204/300], Loss D: 0.2692, Loss G: 266.1463\n","Epoch [205/300], Loss D: 0.1259, Loss G: 328.0980\n","Epoch [206/300], Loss D: 0.1964, Loss G: 340.5339\n","Epoch [207/300], Loss D: 0.1823, Loss G: 221.0744\n","Epoch [208/300], Loss D: 0.0457, Loss G: 184.5788\n","Epoch [209/300], Loss D: 0.1403, Loss G: 211.6519\n","Epoch [210/300], Loss D: 0.1019, Loss G: 217.1530\n","Epoch [211/300], Loss D: 0.2230, Loss G: 212.1776\n","Epoch [212/300], Loss D: 0.2225, Loss G: 209.6765\n","Epoch [213/300], Loss D: 0.0872, Loss G: 232.6497\n","Epoch [214/300], Loss D: 0.1452, Loss G: 228.5538\n","Epoch [215/300], Loss D: 0.1230, Loss G: 187.7922\n","Epoch [216/300], Loss D: 0.1048, Loss G: 191.8825\n","Epoch [217/300], Loss D: 0.2257, Loss G: 239.1861\n","Epoch [218/300], Loss D: 0.0628, Loss G: 191.7222\n","Epoch [219/300], Loss D: 0.1022, Loss G: 236.2919\n","Epoch [220/300], Loss D: 0.0524, Loss G: 154.2079\n","Epoch [221/300], Loss D: 0.1254, Loss G: 182.8941\n","Epoch [222/300], Loss D: 0.2587, Loss G: 224.9490\n","Epoch [223/300], Loss D: 0.1608, Loss G: 217.5835\n","Epoch [224/300], Loss D: 0.1459, Loss G: 216.0924\n","Epoch [225/300], Loss D: 0.1143, Loss G: 218.3474\n","Epoch [226/300], Loss D: 0.0738, Loss G: 212.8750\n","Epoch [227/300], Loss D: 0.2436, Loss G: 253.2681\n","Epoch [228/300], Loss D: 0.1203, Loss G: 310.7490\n","Epoch [229/300], Loss D: 0.1822, Loss G: 254.8252\n","Epoch [230/300], Loss D: 0.1627, Loss G: 235.5714\n","Epoch [231/300], Loss D: 0.0383, Loss G: 298.7528\n","Epoch [232/300], Loss D: 0.2311, Loss G: 314.2652\n","Epoch [233/300], Loss D: 0.4849, Loss G: 196.3862\n","Epoch [234/300], Loss D: 15.1008, Loss G: 12835.9873\n","Epoch [235/300], Loss D: 3.7393, Loss G: 4087.5479\n","Epoch [236/300], Loss D: 0.0891, Loss G: 3318.4880\n","Epoch [237/300], Loss D: 0.7551, Loss G: 2474.2908\n","Epoch [238/300], Loss D: 0.0304, Loss G: 1675.6058\n","Epoch [239/300], Loss D: 0.4557, Loss G: 1909.0869\n","Epoch [240/300], Loss D: 0.8973, Loss G: 2224.8752\n","Epoch [241/300], Loss D: 0.0000, Loss G: 2400.4106\n","Epoch [242/300], Loss D: 0.1729, Loss G: 1311.2499\n","Epoch [243/300], Loss D: 0.2371, Loss G: 1366.7496\n","Epoch [244/300], Loss D: 1.6433, Loss G: 976.2678\n","Epoch [245/300], Loss D: 0.1822, Loss G: 1526.8378\n","Epoch [246/300], Loss D: 0.0510, Loss G: 1556.9937\n","Epoch [247/300], Loss D: 0.7226, Loss G: 1597.5668\n","Epoch [248/300], Loss D: 0.3310, Loss G: 1479.1206\n","Epoch [249/300], Loss D: 0.0285, Loss G: 2140.2529\n","Epoch [250/300], Loss D: 0.2681, Loss G: 2650.5735\n","Epoch [251/300], Loss D: 0.5734, Loss G: 1601.0277\n","Epoch [252/300], Loss D: 0.5715, Loss G: 1994.4055\n","Epoch [253/300], Loss D: 0.0071, Loss G: 1444.7761\n","Epoch [254/300], Loss D: 0.2573, Loss G: 1698.0997\n","Epoch [255/300], Loss D: 0.0000, Loss G: 1499.4358\n","Epoch [256/300], Loss D: 0.0017, Loss G: 1127.0153\n","Epoch [257/300], Loss D: 0.2697, Loss G: 1363.8729\n","Epoch [258/300], Loss D: 0.1151, Loss G: 1402.4957\n","Epoch [259/300], Loss D: 0.1642, Loss G: 1408.7028\n","Epoch [260/300], Loss D: 0.1890, Loss G: 1214.6222\n","Epoch [261/300], Loss D: 0.1046, Loss G: 821.9860\n","Epoch [262/300], Loss D: 0.1147, Loss G: 1154.8671\n","Epoch [263/300], Loss D: 0.1021, Loss G: 839.1710\n","Epoch [264/300], Loss D: 0.2050, Loss G: 1122.3838\n","Epoch [265/300], Loss D: 0.3124, Loss G: 689.6870\n","Epoch [266/300], Loss D: 0.0922, Loss G: 708.5567\n","Epoch [267/300], Loss D: 0.0628, Loss G: 787.7177\n","Epoch [268/300], Loss D: 0.1350, Loss G: 1219.3975\n","Epoch [269/300], Loss D: 0.0405, Loss G: 725.1990\n","Epoch [270/300], Loss D: 0.3202, Loss G: 828.3972\n","Epoch [271/300], Loss D: 0.2511, Loss G: 1346.9067\n","Epoch [272/300], Loss D: 0.1599, Loss G: 1201.0669\n","Epoch [273/300], Loss D: 0.0751, Loss G: 671.2747\n","Epoch [274/300], Loss D: 0.2523, Loss G: 873.9813\n","Epoch [275/300], Loss D: 0.0424, Loss G: 897.0513\n","Epoch [276/300], Loss D: 0.0418, Loss G: 641.3166\n","Epoch [277/300], Loss D: 0.0682, Loss G: 485.1126\n","Epoch [278/300], Loss D: 0.1026, Loss G: 662.1735\n","Epoch [279/300], Loss D: 0.0937, Loss G: 505.4737\n","Epoch [280/300], Loss D: 0.2699, Loss G: 1093.1456\n","Epoch [281/300], Loss D: 0.0070, Loss G: 576.0795\n","Epoch [282/300], Loss D: 0.1890, Loss G: 490.9583\n","Epoch [283/300], Loss D: 0.0284, Loss G: 560.9039\n","Epoch [284/300], Loss D: 0.6735, Loss G: 331.3973\n","Epoch [285/300], Loss D: 0.1282, Loss G: 384.1500\n","Epoch [286/300], Loss D: 0.0191, Loss G: 587.8366\n","Epoch [287/300], Loss D: 0.1610, Loss G: 448.0793\n","Epoch [288/300], Loss D: 0.1642, Loss G: 599.1166\n","Epoch [289/300], Loss D: 0.0200, Loss G: 849.7823\n","Epoch [290/300], Loss D: 0.5642, Loss G: 637.0974\n","Epoch [291/300], Loss D: 0.2948, Loss G: 315.6440\n","Epoch [292/300], Loss D: 0.1205, Loss G: 590.0699\n","Epoch [293/300], Loss D: 0.0789, Loss G: 375.0720\n","Epoch [294/300], Loss D: 0.0213, Loss G: 330.9192\n","Epoch [295/300], Loss D: 0.0200, Loss G: 523.5126\n","Epoch [296/300], Loss D: 0.2554, Loss G: 541.4544\n","Epoch [297/300], Loss D: 0.3625, Loss G: 314.6132\n","Epoch [298/300], Loss D: 0.0874, Loss G: 432.8959\n","Epoch [299/300], Loss D: 0.0884, Loss G: 377.2478\n","Epoch [300/300], Loss D: 0.0175, Loss G: 300.4045\n"]}],"source":["# Training loop\n","for epoch in range(args.epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        # Reshape and add noise\n","        images = images.view(-1, 28*28)\n","\n","        # Train Discriminator\n","        disc_optimizer.zero_grad()\n","\n","        # Label data\n","        outputs = disc(images)\n","        loss_lab = criterion(outputs, labels)\n","\n","        # Unlabeled data (use generator data)\n","        noise = torch.randn(args.batch_size, 100)\n","        gen_data = gen(noise).detach()\n","        outputs_unl = disc(gen_data)\n","        loss_unl = criterion(outputs_unl, torch.zeros_like(outputs_unl))\n","\n","        # Calculate discriminator loss and backprop\n","        disc_loss = loss_lab + args.unlabeled_weight * loss_unl\n","        disc_loss.backward()\n","        disc_optimizer.step()\n","\n","        # Train Generator\n","        gen_optimizer.zero_grad()\n","        gen_data = gen(noise)\n","        gen_loss = criterion(disc(gen_data), torch.ones_like(outputs))\n","        gen_loss.backward()\n","        gen_optimizer.step()\n","\n","    print(f'Epoch [{epoch+1}/{args.epochs}], Loss D: {disc_loss.item():.4f}, Loss G: {gen_loss.item():.4f}')"]},{"cell_type":"code","execution_count":null,"id":"49bc5701-5d3e-4d6f-9e60-e5cdb03cb248","metadata":{"id":"49bc5701-5d3e-4d6f-9e60-e5cdb03cb248"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"61f1f246-dc7d-47ba-9701-e6f0099fc672","metadata":{"id":"61f1f246-dc7d-47ba-9701-e6f0099fc672"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9","language":"python","name":"python3.9"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}